{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import praw\n",
    "import matplotlib.pyplot as plt\n",
    "from praw.models import MoreComments\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from scipy import stats\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Reddit Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_acct = \"Dangerous-Aerie9277\"\n",
    "reddit = praw.Reddit(\n",
    "    client_id= \"ZRu7WVk3cApdBo0iUrkhnA\",\n",
    "    client_secret= \"cueQ2J_LLjOTNmVvIbFaS3ja7PSO3g\",\n",
    "    user_agent=f\"Comment Extraction (by u/{reddit_acct})\",\n",
    ")\n",
    "\n",
    "def get_posts():\n",
    "\n",
    "    sub = reddit.subreddit('legaladvice')\n",
    "    sub_type = sub.top(time_filter=\"month\")\n",
    "\n",
    "    post = {'post_id':[], 'utc':[],'parent_author':[], 'post_title':[],'comment_author':[], 'comment':[]}\n",
    "    \n",
    "    #Get posts and their comments\n",
    "    for submissions in sub_type:\n",
    "        submissions.comments.replace_more()\n",
    "        for comment in submissions.comments.list():\n",
    "            if comment.author is not None and submissions.author is not None:\n",
    "                post['post_id'].append(submissions)\n",
    "                if comment.parent().author is not None:\n",
    "                    post['parent_author'].append(comment.parent().author.name)\n",
    "                else:\n",
    "                    post['parent_author'].append(submissions.author.name)\n",
    "                post['post_title'].append(submissions.title)\n",
    "                post['comment_author'].append(comment.author.name)\n",
    "                post['comment'].append(comment.body)\n",
    "                post['utc'].append(comment.created_utc)\n",
    "       \n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = pd.DataFrame.from_dict(get_posts())\n",
    "top_df = top_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##moderators or other users who don't count as actual posters\n",
    "df = top_df[top_df['parent_author']!='parsnippity']\n",
    "df = df[df['parent_author']!='AutoModerator']\n",
    "df = df[df['comment_author']!='AutoModerator']\n",
    "df = df[df['comment_author']!='LocationBot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = df.copy()\n",
    "posts_segment = posts.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis of Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "posts_segment[\"neg\"] = posts_segment[\"comment\"].map(lambda x: sia.polarity_scores(x)['neg']*(-1))\n",
    "posts_segment[\"pos\"] = posts_segment[\"comment\"].map(lambda x: sia.polarity_scores(x)['pos'])\n",
    "posts_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posts_segment['neg'].mean())\n",
    "print(posts_segment['pos'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get maximum value of absolute values of positive and negative sentiment scores - determines how post will be labeled\n",
    "v = posts_segment[['pos','neg']].values\n",
    "posts_segment['sen_value'] = v[range(len(v)), np.abs(v).argmax(axis=1)]\n",
    "posts_segment['sen'] = posts_segment[['pos','neg']].abs().idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network of Posts\n",
    "Nodes are users and edges are comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.from_pandas_edgelist(posts_segment, source='comment_author', target='parent_author', edge_attr = ['sen_value','sen'], create_using=nx.DiGraph())\n",
    "\n",
    "sen=nx.get_edge_attributes(G,'sen')\n",
    "for i,j in G.edges:\n",
    "    if sen[(i,j)] == 'neg':\n",
    "        G.edges[i,j][\"color\"] = \"red\"\n",
    "    else:\n",
    "        G.edges[i,j][\"color\"] = \"green\"\n",
    "        \n",
    "Gcc = sorted(nx.connected_components(G.to_undirected()), key=len, reverse=True)\n",
    "G0 = G.subgraph(Gcc[0])\n",
    "\n",
    "pos = nx.spring_layout(G0)\n",
    "\n",
    "edges = G0.edges()\n",
    "\n",
    "#Edges colored based on if sentiment of comment is positive or negative\n",
    "color_list = [attrs[\"color\"] for i,j,attrs in G0.edges(data=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx_edges(G0,pos,edge_color=color_list)\n",
    "nx.draw_networkx_nodes(G0, pos, alpha=0.3, node_size = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_generator = nx.community.girvan_newman(G0)\n",
    "top_level_communities = list(next(communities_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each community, get average ratio of positive to negative posts\n",
    "import statistics\n",
    "comm_ratios = []\n",
    "total_lists = [[],[]]\n",
    "for i in range(len(top_level_communities)):\n",
    "    num_pos = 1\n",
    "    num_neg = 1\n",
    "    comm_list = list(top_level_communities[i])\n",
    "    num_comments = 0\n",
    "    for j in comm_list:\n",
    "        sen_list = list(posts_segment.loc[posts_segment['comment_author'] == j, 'sen'])\n",
    "        num_comments += len(sen_list)\n",
    "        for s in sen_list:\n",
    "            if s==\"pos\":\n",
    "                num_pos +=1\n",
    "            else:\n",
    "                num_neg +=1\n",
    "        total_lists[i].append(round(num_pos/num_neg,5))\n",
    "    print(num_comments)\n",
    "    comm_ratios.append(statistics.mean(total_lists[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the sentiment scores for each community:\n",
    "comm1_values = total_lists[0]\n",
    "comm2_values = total_lists[1]\n",
    "\n",
    "# Degrees of freedom  \n",
    "from statistics import mean\n",
    "dof = min(len(comm1_values),len(comm2_values)) - 1\n",
    "\n",
    "print(mean(comm1_values) - mean(comm2_values))\n",
    "## Using SciPy Package  \n",
    "t_stat, p_val = stats.ttest_ind(comm1_values, comm2_values, equal_var = False) \n",
    "print(dof)\n",
    "print(\"t-statistic = \" + str(t_stat))  \n",
    "print(\"p-value = \" + str(p_val))\n",
    "\n",
    "alpha = 0.05\n",
    "if p_val < alpha:\n",
    "    print(\"Reject the null hypothesis; there is a significant difference between the sentiment number ratios of community 1 and community 2.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis; there is no significant difference between the sentiment number ratios of community 1 and community 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each community, get averages sentiment values\n",
    "from statistics import mean \n",
    "comm_value_avgs = []\n",
    "total_value_lists = [[],[]]\n",
    "#for each community, get average sentiment value\n",
    "for i in range(len(top_level_communities)):\n",
    "    total_value = 0\n",
    "    num_comments = 0\n",
    "    comm_list = list(top_level_communities[i])\n",
    "    #for each user, get their average sentiment score\n",
    "    for j in comm_list:\n",
    "        sen_value_list = list(posts_segment.loc[posts_segment['comment_author'] == j, 'sen_value'])\n",
    "        if len(sen_value_list)==0:\n",
    "            pass\n",
    "        else:\n",
    "            mean_value = mean(sen_value_list)\n",
    "            num_comments +=1\n",
    "        total_value+= mean_value\n",
    "        total_value_lists[i].append(mean_value)\n",
    "    comm_value_avgs.append(total_value/num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the sentiment scores for each community:\n",
    "comm1_values = total_value_lists[0]\n",
    "comm2_values = total_value_lists[1]\n",
    "\n",
    "dof = min(len(comm1_values),len(comm2_values)) - 1\n",
    "\n",
    "print(mean(comm1_values) - mean(comm2_values))\n",
    "## Using SciPy Package  \n",
    "t_stat, p_val = stats.ttest_ind(comm1_values, comm2_values, equal_var = False) \n",
    "print(dof)\n",
    "print(\"t-statistic = \" + str(t_stat))  \n",
    "print(\"p-value = \" + str(p_val))\n",
    "\n",
    "alpha = 0.05\n",
    "if p_val < alpha:\n",
    "    print(\"Reject the null hypothesis; there is a significant difference between the sentiment values of community 1 and community 2.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis; there is no significant difference between the sentiment values of community 1 and community 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_segment['date_time'] = posts_segment['utc'].map(lambda x: datetime.fromtimestamp(x))\n",
    "posts_segment['day'] = posts_segment['utc'].map(lambda x: datetime.fromtimestamp(x).day)\n",
    "posts_segment['week'] = posts_segment['utc'].map(lambda x: datetime.fromtimestamp(x).isocalendar()[1])\n",
    "posts_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "ax = sns.histplot(posts_segment[\"date_time\"], bins=30)\n",
    "plt.xticks(rotation=45)\n",
    "ax.set_xticks([\"2023-09-29\",\"2023-10-06\",\"2023-10-13\",\"2023-10-20\",\"2023-10-27\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=posts_segment,x='week',hue='sen')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
